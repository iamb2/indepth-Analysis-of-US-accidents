{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/us-accidents/US_Accidents_Dec19.csv')","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Accidents count (group by States)","metadata":{"trusted":true}},{"cell_type":"code","source":"# create df for state accidents\nimport plotly.graph_objects as go\nstate_count_acc = pd.value_counts(data['State'])\n\nfig = go.Figure(data=go.Choropleth(\n    locations=state_count_acc.index,\n    z = state_count_acc.values.astype(float),\n    locationmode = 'USA-states',\n    colorscale = 'Reds',\n    colorbar_title = \"Count Accidents\",\n))\n\nfig.update_layout(\n    title_text = '2016 - 2019 US Traffic Accident Dataset by State',\n    geo_scope='usa',\n)\n\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## County USA ACCidents","metadata":{}},{"cell_type":"markdown","source":"For county plots we need install plotly-geo","metadata":{}},{"cell_type":"code","source":"!pip install plotly-geo","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here I download special dataset to get county codes:","metadata":{}},{"cell_type":"code","source":"df_county = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/laucnty16.csv')\ndf_county.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_county['county_full'] = df_county['County Name/State Abbreviation'].apply(lambda x: x.split(', ')[0])\ndf_county['county_name'] = df_county['county_full'].apply(lambda x: x.split(' County')[0])\n\ncounty_count_acc = pd.value_counts(data['County'])\nfips_county_df = df_county[['county_name', 'County FIPS Code', 'State FIPS Code']].merge(county_count_acc, left_on='county_name', right_index=True)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.figure_factory as ff\n\nfips_county_df['State FIPS Code'] = fips_county_df['State FIPS Code'].apply(lambda x: str(x).zfill(2))\nfips_county_df['County FIPS Code'] = fips_county_df['County FIPS Code'].apply(lambda x: str(x).zfill(3))\nfips_county_df['FIPS'] = fips_county_df['State FIPS Code'] + fips_county_df['County FIPS Code']\n\ncolorscale = [\"#f7fbff\", \"#ebf3fb\", \"#deebf7\", \"#d2e3f3\", \"#c6dbef\", \"#b3d2e9\", \"#9ecae1\",\n    \"#85bcdb\", \"#6baed6\", \"#57a0ce\", \"#4292c6\", \"#3082be\", \"#2171b5\", \"#1361a9\",\n    \"#08519c\", \"#0b4083\", \"#08306b\"\n]\nendpts = list(np.linspace(1,30000, len(colorscale) - 1))\nfips = fips_county_df['FIPS'].tolist()\nvalues = fips_county_df['County'].tolist()\n\n\nfig = ff.create_choropleth(\n    fips=fips, values=values, scope=['usa'],\n    binning_endpoints=endpts, colorscale=colorscale,\n    show_state_data=False,\n    show_hover=True,\n    asp = 2.9,\n    title_text = 'USA County accidents count',\n    legend_title = 'Accidents count'\n)\nfig.layout.template = None\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Severity accidents","metadata":{}},{"cell_type":"markdown","source":"Here I sample only 10000 points to save memory.","metadata":{}},{"cell_type":"code","source":"data_sever = data.sample(n=10000)\n\nfig = go.Figure(data=go.Scattergeo(\n        locationmode = 'USA-states',\n        lon = data_sever['Start_Lng'],\n        lat = data_sever['Start_Lat'],\n        text = data_sever['City'],\n        mode = 'markers',\n        marker = dict(\n            size = 8,\n            opacity = 0.8,\n            reversescale = True,\n            autocolorscale = False,\n            symbol = 'circle',\n            line = dict(\n                width=1,\n                color='rgba(102, 102, 102)'\n            ),\n            colorscale = 'Reds',\n            cmin = data_sever['Severity'].max(),\n        color = data_sever['Severity'],\n        cmax = 1,\n            colorbar_title=\"Severity\"\n        )))\n\nfig.update_layout(\n        title = 'Severity of accidents',\n        geo = dict(\n            scope='usa',\n            projection_type='albers usa',\n            showland = True,\n            landcolor = \"rgb(250, 250, 250)\",\n            subunitcolor = \"rgb(217, 217, 217)\",\n            countrycolor = \"rgb(217, 217, 217)\",\n            countrywidth = 0.7,\n            subunitwidth = 0.7\n        ),\n    )\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Severity by county","metadata":{}},{"cell_type":"code","source":"county_severity_acc = data[['County','Severity']].groupby('County').mean().reset_index()\nfips_county_sev = df_county[['county_name', 'County FIPS Code', 'State FIPS Code']].merge(county_severity_acc, left_on='county_name', right_on='County')\nfips_county_sev['Severity'] = fips_county_sev['Severity'].apply(lambda x: round(x,1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fips_county_sev['State FIPS Code'] = fips_county_sev['State FIPS Code'].apply(lambda x: str(x).zfill(2))\nfips_county_sev['County FIPS Code'] = fips_county_sev['County FIPS Code'].apply(lambda x: str(x).zfill(3))\nfips_county_sev['FIPS'] = fips_county_sev['State FIPS Code'] + fips_county_sev['County FIPS Code']\n\n\nfips = fips_county_sev['FIPS'].tolist()\nvalues = fips_county_sev['Severity'].tolist()\n\n\nfig = ff.create_choropleth(\n    fips=fips, values=values, scope=['usa'],\n#     binning_endpoints=endpts,\n#     show_state_data=False,\n#     show_hover=True,\n#     asp = 2.9,\n    title_text = 'USA accidents severity (mean)',\n    legend_title = 'Accidents severity'\n)\nfig.layout.template = None\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visibility & Severity","metadata":{}},{"cell_type":"code","source":"data_sever = data.sample(n=10000)[['Start_Lng','Start_Lat','City','Visibility(mi)','Severity']]\ndata_sever.dropna(inplace=True)\n\nfig = go.Figure(data=go.Scattergeo(\n        locationmode = 'USA-states',\n        lon = data_sever['Start_Lng'],\n        lat = data_sever['Start_Lat'],\n        text = data_sever['City'],\n        mode = 'markers',\n        marker = dict(\n            size = data_sever['Visibility(mi)'],\n            opacity = 0.8,\n            reversescale = True,\n            autocolorscale = False,\n            symbol = 'circle',\n            line = dict(\n                width=1,\n                color='rgba(102, 102, 102)'\n            ),\n            colorscale = 'Blues',\n            cmin = data_sever['Severity'].max(),\n        color = data_sever['Severity'],\n        cmax = 1,\n            colorbar_title=\"Severity\"\n        )))\n\nfig.update_layout(\n        title = 'Severity & Visibility of accidents',\n        geo = dict(\n            scope='usa',\n            projection_type='albers usa',\n            showland = True,\n            landcolor = \"rgb(250, 250, 250)\",\n            subunitcolor = \"rgb(217, 217, 217)\",\n            countrycolor = \"rgb(217, 217, 217)\",\n            countrywidth = 0.7,\n            subunitwidth = 0.7\n        ),\n    )\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distance & Severity","metadata":{}},{"cell_type":"code","source":"data_sever = data.sample(n=15000)[['Start_Lng','Start_Lat','City','Distance(mi)','Severity']]\ndata_sever.dropna(inplace=True)\n\nfig = go.Figure(data=go.Scattergeo(\n        locationmode = 'USA-states',\n        lon = data_sever['Start_Lng'],\n        lat = data_sever['Start_Lat'],\n        text = data_sever['City'],\n        mode = 'markers',\n        marker = dict(\n            size = data_sever['Distance(mi)'],\n            opacity = 0.8,\n            reversescale = True,\n            autocolorscale = False,\n            symbol = 'circle',\n            line = dict(\n                width=1,\n                color='rgba(102, 102, 102)'\n            ),\n            colorscale = 'Viridis',\n            cmin = data_sever['Severity'].max(),\n        color = data_sever['Severity'],\n        cmax = 1,\n            colorbar_title=\"Severity\"\n        )))\n\nfig.update_layout(\n        title = 'Severity & Distance of accidents',\n        geo = dict(\n            scope='usa',\n            projection_type='albers usa',\n            showland = True,\n            landcolor = \"rgb(250, 250, 250)\",\n            subunitcolor = \"rgb(217, 217, 217)\",\n            countrycolor = \"rgb(217, 217, 217)\",\n            countrywidth = 0.7,\n            subunitwidth = 0.7\n        ),\n    )\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Classification accidents severity by text description","metadata":{}},{"cell_type":"markdown","source":"Let's do something strange and try to predict accident severity by it's text description :)","metadata":{}},{"cell_type":"code","source":"from more_itertools import sliced\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Embedding, SpatialDropout1D\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks.callbacks import EarlyStopping","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_data = data[['Description','Severity']].sample(n=1000, random_state=10)\ntext_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(15):\n    print(text_data['Description'].iloc[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The maximum number of words to be used. (most frequent)\nMAX_NB_WORDS = 100\n# Max number of words in each complaint.\nMAX_SEQUENCE_LENGTH = 500\n# This is fixed.\nEMBEDDING_DIM = 100\ntokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\ntokenizer.fit_on_texts(text_data['Description'].values)\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = tokenizer.texts_to_sequences(text_data['Description'].values)\nX = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\nprint('Shape of data tensor:', X.shape)\n\nY = pd.get_dummies(text_data['Severity']).values\nprint('Shape of label tensor:', Y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10, random_state = 42)\nprint(X_train.shape,Y_train.shape)\nprint(X_test.shape,Y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\nmodel.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(3, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n# choose epochs and batch_size\nepochs = 15\nbatch_size = 64\nhistory = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.001)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accr = model.evaluate(X_test,Y_test)\nprint('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Loss')\nplt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='test')\nplt.legend()\nplt.show();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### If you like this kernel, upvote it please.","metadata":{}}]}